{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7f46bd0d-b179-4ba1-89c9-1f8f282e373a",
      "metadata": {
        "id": "7f46bd0d-b179-4ba1-89c9-1f8f282e373a",
        "outputId": "c20afc36-fba5-4447-8c25-47f318fe543e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'nbformat': 4,\n",
              " 'nbformat_minor': 0,\n",
              " 'metadata': {'colab': {'provenance': [],\n",
              "   'authorship_tag': 'ABX9TyMJ5SOpLvOTef5xF4uBDKKc',\n",
              "   'include_colab_link': True},\n",
              "  'kernelspec': {'name': 'python3', 'display_name': 'Python 3'},\n",
              "  'language_info': {'name': 'python'}},\n",
              " 'cells': [{'cell_type': 'markdown',\n",
              "   'metadata': {'id': 'view-in-github', 'colab_type': 'text'},\n",
              "   'source': ['<a href=\"https://colab.research.google.com/github/NimalSundar/AI-Project/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>']},\n",
              "  {'cell_type': 'code',\n",
              "   'execution_count': 2,\n",
              "   'metadata': {'colab': {'base_uri': 'https://localhost:5051/'},\n",
              "    'id': '2IDcqL90VCij',\n",
              "    'outputId': 'cb80c9f2-b8c5-435a-a0c4-3668bebdeace'},\n",
              "   'outputs': [{'output_type': 'stream',\n",
              "     'name': 'stdout',\n",
              "     'text': ['\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/42.0 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m\\r\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m42.0/42.0 kB\\x1b[0m \\x1b[31m1.1 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m\\n',\n",
              "      '\\x1b[?25hEnter text to translate: hello\\n',\n",
              "      'Translate to (e.g. French, Hindi, Spanish): Hindi\\n',\n",
              "      '\\n',\n",
              "      '🌐 Translation:\\n',\n",
              "      ' नमस्ते (Namaste) \\n']}],\n",
              "   'source': ['# Install required packages\\n',\n",
              "    '!pip install -q langchain langchain-google-genai google-generativeai\\n',\n",
              "    '\\n',\n",
              "    'import os\\n',\n",
              "    'from langchain_google_genai import ChatGoogleGenerativeAI\\n',\n",
              "    'from langchain.prompts import PromptTemplate\\n',\n",
              "    '\\n',\n",
              "    'os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCXemNjEG8rdEsPptv8CFVv-74B9_FEnVk\"\\n',\n",
              "    '\\n',\n",
              "    'prompt = PromptTemplate(\\n',\n",
              "    '    input_variables=[\"text\", \"target_language\"],\\n',\n",
              "    '    template=\"\"\"\\n',\n",
              "    'You are a professional translator. Translate the following text into {target_language}:\\n',\n",
              "    '\\n',\n",
              "    'Text: {text}\\n',\n",
              "    'Translation:\\n',\n",
              "    '\"\"\"\\n',\n",
              "    ')\\n',\n",
              "    '\\n',\n",
              "    'llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.3)\\n',\n",
              "    'translator = prompt | llm\\n',\n",
              "    '\\n',\n",
              "    '# User input\\n',\n",
              "    'text = input(\"Enter text to translate: \")\\n',\n",
              "    'language = input(\"Translate to (e.g. French, Hindi, Spanish): \")\\n',\n",
              "    '\\n',\n",
              "    'result = translator.invoke({\"text\": text, \"target_language\": language})\\n',\n",
              "    'print(\"\\\\n🌐 Translation:\\\\n\", result.content)\\n']}]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "{\n",
        "  \"nbformat\": 4,\n",
        "  \"nbformat_minor\": 0,\n",
        "  \"metadata\": {\n",
        "    \"colab\": {\n",
        "      \"provenance\": [],\n",
        "      \"authorship_tag\": \"ABX9TyMJ5SOpLvOTef5xF4uBDKKc\",\n",
        "      \"include_colab_link\": True\n",
        "    },\n",
        "    \"kernelspec\": {\n",
        "      \"name\": \"python3\",\n",
        "      \"display_name\": \"Python 3\"\n",
        "    },\n",
        "    \"language_info\": {\n",
        "      \"name\": \"python\"\n",
        "    }\n",
        "  },\n",
        "  \"cells\": [\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"view-in-github\",\n",
        "        \"colab_type\": \"text\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"<a href=\\\"https://colab.research.google.com/github/NimalSundar/AI-Project/blob/main/Untitled1.ipynb\\\" target=\\\"_parent\\\"><img src=\\\"https://colab.research.google.com/assets/colab-badge.svg\\\" alt=\\\"Open In Colab\\\"/></a>\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": 2,\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:5051/\"\n",
        "        },\n",
        "        \"id\": \"2IDcqL90VCij\",\n",
        "        \"outputId\": \"cb80c9f2-b8c5-435a-a0c4-3668bebdeace\"\n",
        "      },\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"\\u001b[?25l   \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m0.0/42.0 kB\\u001b[0m \\u001b[31m?\\u001b[0m eta \\u001b[36m-:--:--\\u001b[0m\\r\\u001b[2K   \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m42.0/42.0 kB\\u001b[0m \\u001b[31m1.1 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\n",
        "            \"\\u001b[?25hEnter text to translate: hello\\n\",\n",
        "            \"Translate to (e.g. French, Hindi, Spanish): Hindi\\n\",\n",
        "            \"\\n\",\n",
        "            \"🌐 Translation:\\n\",\n",
        "            \" नमस्ते (Namaste) \\n\"\n",
        "          ]\n",
        "        }\n",
        "      ],\n",
        "      \"source\": [\n",
        "        \"# Install required packages\\n\",\n",
        "        \"!pip install -q langchain langchain-google-genai google-generativeai\\n\",\n",
        "        \"\\n\",\n",
        "        \"import os\\n\",\n",
        "        \"from langchain_google_genai import ChatGoogleGenerativeAI\\n\",\n",
        "        \"from langchain.prompts import PromptTemplate\\n\",\n",
        "        \"\\n\",\n",
        "        \"os.environ[\\\"GOOGLE_API_KEY\\\"] = \\\"AIzaSyCXemNjEG8rdEsPptv8CFVv-74B9_FEnVk\\\"\\n\",\n",
        "        \"\\n\",\n",
        "        \"prompt = PromptTemplate(\\n\",\n",
        "        \"    input_variables=[\\\"text\\\", \\\"target_language\\\"],\\n\",\n",
        "        \"    template=\\\"\\\"\\\"\\n\",\n",
        "        \"You are a professional translator. Translate the following text into {target_language}:\\n\",\n",
        "        \"\\n\",\n",
        "        \"Text: {text}\\n\",\n",
        "        \"Translation:\\n\",\n",
        "        \"\\\"\\\"\\\"\\n\",\n",
        "        \")\\n\",\n",
        "        \"\\n\",\n",
        "        \"llm = ChatGoogleGenerativeAI(model=\\\"gemini-1.5-pro\\\", temperature=0.3)\\n\",\n",
        "        \"translator = prompt | llm\\n\",\n",
        "        \"\\n\",\n",
        "        \"# User input\\n\",\n",
        "        \"text = input(\\\"Enter text to translate: \\\")\\n\",\n",
        "        \"language = input(\\\"Translate to (e.g. French, Hindi, Spanish): \\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"result = translator.invoke({\\\"text\\\": text, \\\"target_language\\\": language})\\n\",\n",
        "        \"print(\\\"\\\\n🌐 Translation:\\\\n\\\", result.content)\\n\"\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "cell_execution_strategy": "setup"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}